---
layout: post
title:  "Important Links and Papers"
date:   2016-09-08 19:24:38 +0530
categories: welcome
---
Useful Links:
* [Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
* [Tensor Flow](https://www.tensorflow.org/)

Some Relevant Papers:
* [Long Short Term Memory (Original Paper)](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)
* [Generating Sequences With Recurrent Neural Networks](http://arxiv.org/pdf/1308.0850.pdf)
* Why LSTM?
  + In theory, RNNs are absolutely capable of handling such _long-term dependencies._ A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don’t seem to be able to learn them. Thankfully, LSTMs don’t have this problem!  
  [Learning Long Term Dependencies With Gradient Descent is Difficult](http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf)
